{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb763e6d",
   "metadata": {},
   "source": [
    "# 第七章 - 深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ca28a",
   "metadata": {},
   "source": [
    "## 7.1 CNN类深度网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8609b1",
   "metadata": {},
   "source": [
    "### 7.1.1 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07d53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e961a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D-CNN模型定义\n",
    "class Simple1DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple1DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 50, 64)  # 假设输入序列的长度为100\n",
    "        self.fc2 = nn.Linear(64, 10)       # 假设输出类别数为10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 16 * 50)  # 将多维输入一维化\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bb28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试数据\n",
    "# 假设输入维度为(batch_size, channels, sequence_length)\n",
    "batch_size = 2\n",
    "channels = 1\n",
    "sequence_length = 100\n",
    "test_input = torch.randn(batch_size, channels, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad045ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 10])\n",
      "Output tensor: tensor([[-0.3385,  0.0440, -0.1097, -0.0110, -0.1404, -0.3486, -0.1274, -0.2438,\n",
      "          0.1753, -0.1129],\n",
      "        [-0.2386,  0.0682, -0.3389, -0.0713, -0.1648, -0.3605, -0.1303,  0.0037,\n",
      "          0.4261, -0.1400]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 创建模型实例\n",
    "model = Simple1DCNN()\n",
    "\n",
    "# 执行模型前向传播\n",
    "output = model(test_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output tensor:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94284f7",
   "metadata": {},
   "source": [
    "### 7.1.2 Wavenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ef0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c1ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义WaveNet的一个因果卷积层\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                                padding=self.padding, dilation=dilation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        return x[:, :, :-self.padding]  # 移除多余的padding\n",
    "\n",
    "# 定义WaveNet的残差块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, residual_channels, skip_channels, dilation):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.dilated_conv = CausalConv1d(residual_channels, 2 * residual_channels, kernel_size=2, dilation=dilation)\n",
    "        self.conv_res = nn.Conv1d(residual_channels, residual_channels, kernel_size=1)\n",
    "        self.conv_skip = nn.Conv1d(residual_channels, skip_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.dilated_conv(x)\n",
    "        x = F.tanh(x[:, :res.size(1), :]) * F.sigmoid(x[:, res.size(1):, :])\n",
    "        skip = self.conv_skip(x)\n",
    "        res = res + self.conv_res(x)\n",
    "        return res, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义完整的WaveNet模型\n",
    "# 注意：该样例代码没有加入条件输入和门控激活函数\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_layers, residual_channels, skip_channels, num_classes):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_layers = num_layers\n",
    "        self.front_conv = nn.Conv1d(1, residual_channels, kernel_size=1)\n",
    "        self.res_blocks = nn.ModuleList()\n",
    "        for b in range(num_blocks):\n",
    "            for l in range(num_layers):\n",
    "                self.res_blocks.append(ResidualBlock(residual_channels, skip_channels, 2**l))\n",
    "        self.skip_conv = nn.Conv1d(skip_channels, skip_channels, kernel_size=1)\n",
    "        self.fc = nn.Conv1d(skip_channels, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.front_conv(x)\n",
    "        skip_connections = []\n",
    "        for res_block in self.res_blocks:\n",
    "            x, skip = res_block(x)\n",
    "            skip_connections.append(skip)\n",
    "        x = sum(skip_connections)\n",
    "        x = F.relu(x)\n",
    "        x = self.skip_conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9bbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例\n",
    "num_blocks = 3\n",
    "num_layers = 10\n",
    "residual_channels = 32\n",
    "skip_channels = 64\n",
    "num_classes = 256 \n",
    "model = WaveNet(num_blocks, num_layers, residual_channels, skip_channels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84c63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "batch_size = 5\n",
    "sequence_length = 16000  # 数据长度\n",
    "test_data = torch.randn(batch_size, 1, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d01af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 256, 16000])\n"
     ]
    }
   ],
   "source": [
    "# 运行模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(test_data)\n",
    "\n",
    "print(output.size())  # 输出应该是(batch_size, num_classes, sequence_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e362b03",
   "metadata": {},
   "source": [
    "## 7.2 RNN类深度网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab3e40",
   "metadata": {},
   "source": [
    "### 7.2.1 ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76a8093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a17cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义回声神经网络结构\n",
    "class EchoStateNetwork(nn.Module):\n",
    "    def __init__(self, input_size, reservoir_size, output_size):\n",
    "        super(EchoStateNetwork, self).__init__()\n",
    "        \n",
    "        # 初始化输入层到reservoir的权重\n",
    "        self.input_weights = nn.Parameter(torch.randn(input_size, reservoir_size) * 0.1, requires_grad=False)\n",
    "        \n",
    "        # 初始化reservoir内部的权重\n",
    "        self.reservoir_weights = nn.Parameter(torch.rand(reservoir_size, reservoir_size) - 0.5, requires_grad=False)\n",
    "        # 保证reservoir的回声状态属性 (spectral radius < 1)\n",
    "        self.reservoir_weights.data *= 0.9 / torch.max(torch.abs(torch.linalg.eigvals(self.reservoir_weights.data)))\n",
    "        \n",
    "        # 输出层权重将在训练过程中更新\n",
    "        self.output_weights = nn.Parameter(torch.randn(reservoir_size, output_size) * 0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 初始化reservoir状态\n",
    "        batch_size, sequence_length, _ = x.size()\n",
    "        h = torch.zeros(batch_size, self.reservoir_weights.size(0), device=x.device)\n",
    "        \n",
    "        # 计算reservoir的状态\n",
    "        for t in range(sequence_length):\n",
    "            h = torch.tanh(x[:,t] @ self.input_weights + h @ self.reservoir_weights)\n",
    "        \n",
    "        # 计算输出层\n",
    "        y = h @ self.output_weights\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c482bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据生成\n",
    "def generate_test_data(sequence_length, batch_size, input_size, output_size):\n",
    "    # 随机生成一些输入数据\n",
    "    x = torch.randn(batch_size, sequence_length, input_size)\n",
    "    # 生成输出数据，这里只是简单地用随机数代替\n",
    "    y = torch.randn(batch_size, output_size)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57eec646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试ESN模型\n",
    "input_size = 10\n",
    "reservoir_size = 100\n",
    "output_size = 1\n",
    "sequence_length = 20\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941bdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成测试数据\n",
    "x, y_true = generate_test_data(sequence_length, batch_size, input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a76294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建ESN实例\n",
    "esn = EchoStateNetwork(input_size, reservoir_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60956c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output: tensor([[ 0.3731],\n",
      "        [-0.0515],\n",
      "        [-0.4167],\n",
      "        [ 0.1139],\n",
      "        [ 0.3155]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 执行模型\n",
    "y_pred = esn(x)\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"Predicted output:\", y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72adec73",
   "metadata": {},
   "source": [
    "### 7.2.2 TPA-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be2943bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bfab652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义TPA-LSTM模型结构\n",
    "class TemporalPatternAttention(nn.Module):\n",
    "    def __init__(self, input_size, time_steps):\n",
    "        super(TemporalPatternAttention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.time_steps = time_steps\n",
    "        self.W = nn.Parameter(torch.Tensor(input_size, input_size))\n",
    "        self.U = nn.Parameter(torch.Tensor(input_size, input_size))\n",
    "        self.b = nn.Parameter(torch.Tensor(input_size))\n",
    "        self.v = nn.Parameter(torch.Tensor(input_size, 1))\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for param in self.parameters():\n",
    "            nn.init.normal_(param, mean=0, std=0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, time_steps, input_size)\n",
    "        Ux = torch.tanh(torch.matmul(x, self.W) + torch.matmul(x.mean(dim=1, keepdim=True), self.U) + self.b)\n",
    "        # Ux shape: (batch_size, time_steps, input_size)\n",
    "        vu = torch.matmul(Ux, self.v)\n",
    "        # vu shape: (batch_size, time_steps, 1)\n",
    "        alphas = F.softmax(vu, dim=1)\n",
    "        # alphas shape: (batch_size, time_steps, 1)\n",
    "        output = x * alphas\n",
    "        # output shape: (batch_size, time_steps, input_size)\n",
    "        return output, alphas\n",
    "\n",
    "class TPA_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, time_steps, num_layers=1):\n",
    "        super(TPA_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.time_steps = time_steps\n",
    "        self.input_size = input_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = TemporalPatternAttention(hidden_size, time_steps)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, time_steps, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out shape: (batch_size, time_steps, hidden_size)\n",
    "        attn_out, alphas = self.attention(lstm_out)\n",
    "        # attn_out shape: (batch_size, time_steps, hidden_size)\n",
    "        # alphas shape: (batch_size, time_steps, 1)\n",
    "        out = attn_out[:, -1, :]  # We only take the output from the last time step\n",
    "        # out shape: (batch_size, hidden_size)\n",
    "        out = self.fc(out)\n",
    "        # out shape: (batch_size, 1)\n",
    "        return out, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aad59ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "time_steps = 10\n",
    "input_size = 5\n",
    "hidden_size = 64\n",
    "batch_size = 32\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e36be5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPA-LSTM 模型实例\n",
    "model = TPA_LSTM(input_size=input_size, hidden_size=hidden_size, time_steps=time_steps, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f42bb34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "test_data = torch.rand(batch_size, time_steps, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebae8932",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出形状: torch.Size([32, 1])\n",
      "输出: tensor([[-0.0256],\n",
      "        [-0.0261],\n",
      "        [-0.0263],\n",
      "        [-0.0263],\n",
      "        [-0.0264],\n",
      "        [-0.0258],\n",
      "        [-0.0257],\n",
      "        [-0.0255],\n",
      "        [-0.0259],\n",
      "        [-0.0257],\n",
      "        [-0.0256],\n",
      "        [-0.0249],\n",
      "        [-0.0258],\n",
      "        [-0.0261],\n",
      "        [-0.0258],\n",
      "        [-0.0253],\n",
      "        [-0.0262],\n",
      "        [-0.0261],\n",
      "        [-0.0258],\n",
      "        [-0.0260],\n",
      "        [-0.0258],\n",
      "        [-0.0265],\n",
      "        [-0.0262],\n",
      "        [-0.0266],\n",
      "        [-0.0250],\n",
      "        [-0.0248],\n",
      "        [-0.0262],\n",
      "        [-0.0251],\n",
      "        [-0.0268],\n",
      "        [-0.0264],\n",
      "        [-0.0264],\n",
      "        [-0.0254]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 模型输出\n",
    "output, alphas = model(test_data)\n",
    "\n",
    "print(\"输出形状:\", output.shape)\n",
    "print(\"输出:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54ee00",
   "metadata": {},
   "source": [
    "### 7.2.3 DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR 模型使用GluonTS的接口实现，具体可以参考\n",
    "# https://ts.gluon.ai/stable/api/gluonts/gluonts.mx.model.deepar.html?highlight=deeparestimator#gluonts.mx.model.deepar.DeepAREstimator\n",
    "import mxnet as mx\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.mx.trainer import Trainer\n",
    "from gluonts.dataset.common import ListDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16419f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以确保可重复性\n",
    "np.random.seed(42)\n",
    "mx.random.seed(42)\n",
    "\n",
    "# 创建合成测试数据\n",
    "num_series = 10\n",
    "num_steps = 24\n",
    "prediction_length = 7\n",
    "freq = '1H'  # 每小时一个数据点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d8b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(num_series):\n",
    "    ts = pd.date_range(start='2020-01-01', periods=num_steps, freq=freq)\n",
    "    values = np.random.rand(len(ts))\n",
    "    data.append({'start': ts[0], 'target': values[:-prediction_length]})\n",
    "    \n",
    "# 使用ListDataset创建GluonTS数据集\n",
    "test_data = ListDataset(data, freq=freq, one_dim_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Deepar模型的超参数\n",
    "estimator = DeepAREstimator(\n",
    "    freq=freq,\n",
    "    prediction_length=prediction_length,\n",
    "    trainer=Trainer(epochs=5)  # 训练5个epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "predictor = estimator.train(training_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型进行预测\n",
    "for test_entry, forecast in zip(test_data, predictor.predict(test_data)):\n",
    "    print(forecast.mean)\n",
    "    # 这里使用mean，也可以使用其他分位数，例如.quantile(0.7) -> 70分位数预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f215e",
   "metadata": {},
   "source": [
    "### 7.2.4 LSTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1bbcf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "20c23767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTNet 模型\n",
    "class LSTNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, kernel_size, cnn_out_channels):\n",
    "        super(LSTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=cnn_out_channels, kernel_size=kernel_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.gru = nn.GRU(cnn_out_channels, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layer\n",
    "        c = x.view(x.size(0), x.size(2), -1)  # (batch, input_size, seq_len)\n",
    "        c = self.conv1(c)\n",
    "        c = self.relu(c)\n",
    "        \n",
    "        # GRU layer\n",
    "        r = c.permute(2, 0, 1)  # (seq_len, batch, cnn_out_channels)\n",
    "        _, h = self.gru(r)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        out = self.fc(h.squeeze(0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "acdb0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 参数设置\n",
    "input_size = 1  # 输入特征的维度\n",
    "hidden_size = 10  # GRU隐藏层的维度\n",
    "output_size = 1  # 输出特征的维度\n",
    "kernel_size = 2  # CNN的卷积核大小\n",
    "cnn_out_channels = 5  # CNN输出的通道数\n",
    "seq_length = 10  # 序列的长度\n",
    "batch_size = 16  # 批次大小\n",
    "epochs = 5  # 训练轮数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d9c39f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# 生成随机数据作为输入\n",
    "x = np.random.randn(100, seq_length, input_size).astype(np.float32)\n",
    "y = np.random.randn(100, output_size).astype(np.float32)\n",
    "\n",
    "# 转化为tensor\n",
    "x_tensor = torch.from_numpy(x)\n",
    "y_tensor = torch.from_numpy(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4696bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DataLoader\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 实例化模型\n",
    "model = LSTNet(input_size, hidden_size, output_size, kernel_size, cnn_out_channels)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffb43968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(data_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d81bb43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[-0.05802027]\n",
      " [-0.02585397]\n",
      " [ 0.07551305]\n",
      " [-0.00784112]\n",
      " [-0.00163513]\n",
      " [ 0.00550213]\n",
      " [ 0.0008548 ]\n",
      " [-0.04464719]\n",
      " [-0.04730664]\n",
      " [-0.03543879]\n",
      " [-0.02438176]\n",
      " [-0.04572471]\n",
      " [-0.02713918]\n",
      " [-0.04959046]\n",
      " [-0.02132425]\n",
      " [-0.04947438]]\n",
      "Actual targets: [[-0.2311016 ]\n",
      " [-1.8180777 ]\n",
      " [ 0.18949963]\n",
      " [-0.04932407]\n",
      " [-0.8000825 ]\n",
      " [ 0.41839802]\n",
      " [ 3.1709747 ]\n",
      " [ 0.67746216]\n",
      " [ 1.0490932 ]\n",
      " [-1.4299912 ]\n",
      " [ 0.20147994]\n",
      " [ 0.16155927]\n",
      " [-0.2069447 ]\n",
      " [-0.9872867 ]\n",
      " [ 0.22425222]\n",
      " [ 2.1495745 ]]\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "# 假设我们用最后一个batch的数据作为测试数据\n",
    "test_inputs, test_targets = next(iter(data_loader))\n",
    "predictions = model(test_inputs)\n",
    "print(\"Predictions:\", predictions.detach().numpy())\n",
    "print(\"Actual targets:\", test_targets.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20af86f",
   "metadata": {},
   "source": [
    "## 7.3 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dca80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c079ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f8ac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a7c685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6be78a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29fe28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3bb1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7319c9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e59551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本编码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7cadc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9b3c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a93fcb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基本解码器接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4aeef59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60865a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbd0a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c2f7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 准备数据，本次使用d2l提供的英文-法语数据集\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "                           '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def read_data_nmt():\n",
    "    \"\"\"载入“英语－法语”数据集\"\"\"\n",
    "    data_dir = d2l.download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "             encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8567c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "# 定义参数\n",
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "# 获取测试数据 \n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "\n",
    "# 定义模型\n",
    "net = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d308a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()      # 损失函数的标量进行“反向传播”\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f1a5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31644b02",
   "metadata": {},
   "source": [
    "## 7.4 N-beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b4d6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e43e823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeatsBlock(nn.Module):\n",
    "    def __init__(self, input_size, theta_size, hidden_units, layers):\n",
    "        super(NBeatsBlock, self).__init__()\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(input_size if i == 0 else hidden_units, hidden_units) for i in range(layers)])\n",
    "        self.fc_theta = nn.Linear(hidden_units, theta_size)\n",
    "        self.backcast_length = input_size\n",
    "        self.forecast_length = theta_size - input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_input = x\n",
    "        for layer in self.fc_layers:\n",
    "            block_input = torch.relu(layer(block_input))\n",
    "        theta = self.fc_theta(block_input)\n",
    "        backcast = theta[:, :self.backcast_length]\n",
    "        forecast = theta[:, self.backcast_length:]\n",
    "        return backcast, forecast\n",
    "\n",
    "class NBeats(nn.Module):\n",
    "    def __init__(self, input_size, theta_size, hidden_units, layers, blocks):\n",
    "        super(NBeats, self).__init__()\n",
    "        self.blocks = nn.ModuleList([NBeatsBlock(input_size, theta_size, hidden_units, layers) for _ in range(blocks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        backcasts = []\n",
    "        forecasts = []\n",
    "        for block in self.blocks:\n",
    "            backcast, forecast = block(x)\n",
    "            backcasts.append(backcast)\n",
    "            forecasts.append(forecast)\n",
    "            x = x - backcast\n",
    "        return torch.stack(backcasts), torch.sum(torch.stack(forecasts), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "676dbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "input_size = 10  # Number of past time steps used as input\n",
    "output_size = 5  # Number of future time steps to predict\n",
    "hidden_units = 512\n",
    "layers = 4\n",
    "blocks = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f189811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "nbeats = NBeats(input_size, input_size + output_size, hidden_units, layers, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ec684da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "batch_size = 16\n",
    "num_samples = 100\n",
    "X = torch.randn(batch_size, num_samples, input_size)\n",
    "y = torch.randn(batch_size, num_samples, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ceeabc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9286693334579468\n",
      "Epoch 2/10, Loss: 0.9149163961410522\n",
      "Epoch 3/10, Loss: 0.9017965197563171\n",
      "Epoch 4/10, Loss: 0.9096616506576538\n",
      "Epoch 5/10, Loss: 0.9134806394577026\n",
      "Epoch 6/10, Loss: 0.9015148878097534\n",
      "Epoch 7/10, Loss: 0.8723934292793274\n",
      "Epoch 8/10, Loss: 0.8574414253234863\n",
      "Epoch 9/10, Loss: 0.8507696986198425\n",
      "Epoch 10/10, Loss: 0.8287347555160522\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(nbeats.parameters())\n",
    "\n",
    "# 开始训练\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for i in range(num_samples):\n",
    "        optimizer.zero_grad()\n",
    "        backcasts, forecast = nbeats(X[:, i, :])\n",
    "        loss = criterion(forecast, y[:, i, :])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9127932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(batch_size, input_size)\n",
    "    _, forecast = nbeats(test_input)\n",
    "    print(f'Forecast: {forecast}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd19d1d",
   "metadata": {},
   "source": [
    "## 7.5 Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b72673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prophet使用facebook实现的api接口\n",
    "from prophet import Prophet\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46e16c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "# Prophet需要两列: 'ds' 和 'y'\n",
    "ds = pd.date_range(start='2021-01-01', periods=365, freq='D')\n",
    "y = (pd.Series(range(365)) + pd.Series(range(365)).apply(lambda x: x*0.1)) + \\\n",
    "    pd.Series(np.random.normal(0, 2, 365))  # 简单的线性增长加上一些噪声\n",
    "df = pd.DataFrame({'ds': ds, 'y': y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4465e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:cmdstanpy:start chain 1\n",
      "INFO:cmdstanpy:finish chain 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x16180f070>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化Prophet模型\n",
    "model = Prophet()\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "529e6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建未来数据框架\n",
    "future = model.make_future_dataframe(periods=365)\n",
    "\n",
    "# 预测未来\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a04ff918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ds     trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
      "0 2021-01-01  0.438672   -1.884259    3.020923     0.438672     0.438672   \n",
      "\n",
      "   additive_terms  additive_terms_lower  additive_terms_upper    weekly  \\\n",
      "0        0.180405              0.180405              0.180405  0.180405   \n",
      "\n",
      "   weekly_lower  weekly_upper  multiplicative_terms  \\\n",
      "0      0.180405      0.180405                   0.0   \n",
      "\n",
      "   multiplicative_terms_lower  multiplicative_terms_upper      yhat  \n",
      "0                         0.0                         0.0  0.619077  \n"
     ]
    }
   ],
   "source": [
    "print(forecast.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285d4c2",
   "metadata": {},
   "source": [
    "## 7.6 Neural-Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac7ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24692619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数据\n",
    "# 假设我们创建一个简单的时间序列，这个时间序列有一个线性趋势和一个年度周期性。\n",
    "def create_test_data(periods=365):\n",
    "    dates = pd.date_range(start='2020-01-01', periods=periods)\n",
    "    trend = pd.Series(range(periods), index=dates)\n",
    "    seasonality = pd.Series(10 * np.sin(np.linspace(0, 2 * np.pi * periods / 365, periods)), index=dates)\n",
    "    data = pd.DataFrame({'ds': dates, 'y': trend + seasonality})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165fa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "df = create_test_data()\n",
    "\n",
    "# 初始化 NeuralProphet 模型\n",
    "m = NeuralProphet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a286ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (NP.forecaster.fit) - When Global modeling with local normalization, metrics are displayed in normalized scale.\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 278\n",
      "WARNING - (NP.config.set_lr_finder_args) - Learning rate finder: The number of batches (23) is too small than the required number for the learning rate finder (216). The results might not be optimal.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f1dabb6942487fa9db61cd7e5cba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f7a5598a16455cbe5c86c98cf84c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 99.726% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 96.667% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency D corresponds to 96.667% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98d9614ce284c27b6345bc77380fd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 23it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils.return_df_in_original_format) - Returning df with no ID column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ds       yhat1\n",
      "0  2020-12-31  363.447693\n",
      "1  2021-01-01  364.563782\n",
      "2  2021-01-02  365.703064\n",
      "3  2021-01-03  366.840515\n",
      "4  2021-01-04  367.978058\n",
      "5  2021-01-05  369.106140\n",
      "6  2021-01-06  370.063385\n",
      "7  2021-01-07  371.150024\n",
      "8  2021-01-08  372.266205\n",
      "9  2021-01-09  373.405365\n",
      "10 2021-01-10  374.542847\n",
      "11 2021-01-11  375.680481\n",
      "12 2021-01-12  376.808441\n",
      "13 2021-01-13  377.765778\n",
      "14 2021-01-14  378.852356\n",
      "15 2021-01-15  379.968536\n",
      "16 2021-01-16  381.107788\n",
      "17 2021-01-17  382.245178\n",
      "18 2021-01-18  383.382782\n",
      "19 2021-01-19  384.510864\n",
      "20 2021-01-20  385.468109\n",
      "21 2021-01-21  386.554749\n",
      "22 2021-01-22  387.670837\n",
      "23 2021-01-23  388.810120\n",
      "24 2021-01-24  389.947571\n",
      "25 2021-01-25  391.085114\n",
      "26 2021-01-26  392.213196\n",
      "27 2021-01-27  393.170532\n",
      "28 2021-01-28  394.257080\n",
      "29 2021-01-29  395.373260\n",
      "            MAE        RMSE      Loss  RegLoss  epoch\n",
      "0    461.119720  546.455994  0.619706      0.0      0\n",
      "1    455.449982  538.055664  0.608181      0.0      1\n",
      "2    447.833893  530.522949  0.594287      0.0      2\n",
      "3    440.448669  522.635437  0.580472      0.0      3\n",
      "4    431.393036  514.800720  0.563671      0.0      4\n",
      "..          ...         ...       ...      ...    ...\n",
      "273    1.205764    2.005930  0.000011      0.0    273\n",
      "274    1.207948    1.947373  0.000011      0.0    274\n",
      "275    1.208594    2.070095  0.000011      0.0    275\n",
      "276    1.208000    2.081732  0.000011      0.0    276\n",
      "277    1.206572    2.080381  0.000011      0.0    277\n",
      "\n",
      "[278 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 拟合模型\n",
    "metrics = m.fit(df, freq='D')\n",
    "\n",
    "# 进行预测\n",
    "future = m.make_future_dataframe(df, periods=30)\n",
    "forecast = m.predict(future)\n",
    "\n",
    "# 打印预测结果\n",
    "print(forecast[['ds', 'yhat1']])  # 'yhat1' 是预测值的列名\n",
    "\n",
    "# 如果你想查看模型的训练和验证损失，可以查看 metrics\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfaa627",
   "metadata": {},
   "source": [
    "## 7.7 Informer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a671c",
   "metadata": {},
   "source": [
    "Informer 可以参考论文作者的原始实现 https://github.com/zhouhaoyi/Informer2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
